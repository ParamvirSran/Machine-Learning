{"cells":[{"cell_type":"markdown","metadata":{"id":"arJO0OUNMoBn"},"source":["---\n","# <span style=\"color:pink\">DS3000B - DS9000B Midterm Exam</span>\n","\n","## <span style=\"color:pink\">Student ID #: _________</span>\n","\n","## <span style=\"color:pink\">Grade: __ / 100</span>\n","\n","## <span style=\"color:pink\">General Comments</span>\n","\n","- This exam integrates knowledge and skills acquired in the first half of the term.\n","\n","- Using AI agents/chatbots such as ChatGPT and Copilot is considered an act of cheating and you will receive 0 mark for the exam.\n","\n","- You are allowed to use any other resources on your computer or the internet, but you are **not** allowed to share documents, post questions to forums such as Stack Overflow (this includes use of homework helpers such as Chegg), or communicate in anyway with people inside or outside the exam room.\n","\n","- Having any communication tools (*e.g.*, Discord, Teams, Slack, Outlook etc.) either web-based or app-based open on your computer (or having them running in the background) is considered an act of cheating and you will receive 0 mark for the exam.\n","\n","- To finish the midterm in the alloted time, you will have to work efficiently.\n","\n","- Please read the entirety of each question carefully.\n","\n","- You must have your work submitted by 6:30PM to the \"Assignments\" section of the course's site on OWL, *i.e.*, the same place where you originally downloaded the notebook. Late submissions will be scored with 0 mark unless one has an approved accommodation for submitting late.\n","\n","- To avoid technical difficulties at the time of submission, please initiate your submission process at the latest five minutes before the deadline.\n","\n","- Some questions demand a **written answer**. Please answer these in full English sentences in a markdown cell right underneath the question.\n","\n","- For your figures ensure that all axes are labeled in an informative way.\n","\n","- At the end, before submitting to OWL, restart the kernel and rerun all cells to make sure that your notebook runs error free and as expected.\n","\n","## <span style=\"color:pink\">Additional Guidance</span>\n","\n","- If at any point you are asking yourself \"are we supposed to...\", write your assumptions clearly and proceed according to them.\n","\n","- If you have no clue how to approach a question, skip it, and move on. Revisit the skipped one(s) after you are done with other questions.\n","\n","- Where applicable, take advantage of the argument `n_jobs=-1` to speed up processes with parallel computing.\n","\n","- To navigate within the notebook, better to take advantage of the notebook's table of contents (normally on the left side of the screen). It saves you some time compared to pure scrolling with the mouse. In VScode, it is nested under the \"OUTLINE\" tab which is by default minimized unless you click it to maximize.\n","\n","- Please ensure that your results are generated using the provided random seed, where applicable."]},{"cell_type":"markdown","metadata":{"id":"ZUchu0x2MoBq"},"source":["---\n","## <span style=\"color:orange\">Toolbox</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ler-47lJMoBq"},"outputs":[],"source":["from datetime import datetime\n","import numpy as np\n","seed = 240229\n","np.random.seed(seed)\n","import pandas as pd\n","pd.set_option('display.max_columns', None)\n","from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, train_test_split\n","from sklearn.metrics import  auc, roc_curve, roc_auc_score, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from IPython.display import display"]},{"cell_type":"markdown","metadata":{"id":"4AAgNfleMoBs"},"source":["---\n","## Question 1 - <span style=\"color:red\">[70]</span> - Classification\n","For this question you will be working with \"Data_Q1.csv\", which is a dataset on property price. Below, we provide a detailed description of each variable in the dataset:\n","\n","|Column Index | Attribute | Description |\n","| --- | --- | --- |\n","| 0|ID|Property's identification number|\n","| 1|MSSubClass|Building class|\n","| 2|LotArea|Lot size in square feet|\n","| 3|LandSlope|Slope of property's land|\n","| 4|HouseStyle|Style of dwelling|\n","| 5|OverallQual|Overall material and finish quality|\n","| 6|OverallCond|Overall condition rating|\n","| 7|YearBuilt|Original construction date|\n","| 8|MasVnrArea|Masonry veneer walls area in square feet|\n","| 9|TotalBsmtSF|Total square feet of basement area|\n","|10|Heating|Type of heating|\n","|11|CentralAir|Central air conditioning|\n","|12|1stFlrSF|First Floor square feet|\n","|13|2ndFlrSF|Second floor square feet|\n","|14|GrLivArea|Above grade (ground) living area square feet|\n","|15|FullBath|Full bathrooms above grade|\n","|16|HalfBath|Half baths above grade|\n","|17|BedroomAbvGr|Number of bedrooms above basement level|\n","|18|TotRmsAbvGrd|Total rooms above grade (does not include bathrooms)|\n","|19|Fireplaces|Number of fireplaces|\n","|20|GarageCars|Size of garage in car capacity|\n","|21|GarageArea|Size of garage in square feet|\n","|22|PavedDrive|Paved driveway|\n","|23|WoodDeckSF|Wood deck area in square feet|\n","|24|OpenPorchSF|Open porch area in square feet|\n","|25|MiscVal|$ value of miscellaneous feature|\n","|26|YrSold|Year sold|\n","|27|SalePrice|Sale price in dollars|"]},{"cell_type":"markdown","metadata":{"id":"l3EBf7m4MoBt"},"source":["### Q1.1 - <span style=\"color:red\">[20]</span> - Data preparation\n","Load the dataset as a pandas dataframe and perform the following steps:\n","1. Display its first five rows. <span style=\"color:green\">[2]</span>\n","2. Print out the number of rows and columns of it? <span style=\"color:green\">[2]</span>\n","3. Print out the count for each variable type? For example, if you have a dataframe with 5 columns of which 2 are `int64` and 3 are `float64`, your printed output will be like: `float64` 3, `int64` 2. <span style=\"color:green\">[2]</span>\n","4. Print out the count of rows with missing values. Drop those rows from the dataframe, if any. <span style=\"color:green\">[2]</span>\n","5. Remove the `Id` column from your dataframe. <span style=\"color:green\">[2]</span>\n","6. Find the age of the properties using `YearBuilt` variable and replace `YearBuilt` with the new variable `PropertyAge`. For this purpose, use the current year as reference. <span style=\"color:green\">[2]</span>\n","7. Use `YrSold` variable to calculate how many years ago the property was sold and name that new coulmn `YrsSinceSale` and replace `YrSold`. <span style=\"color:green\">[2]</span>\n","8. Encode all categorical columns using One-hot encoding. We want to get $k-1$ dummies out of $k$ categorical levels. How many new columns were added to the dataframe? <span style=\"color:green\">[2]</span>\n","9. Eventually, we want to do a binary classification of properties based on their `SalePrice`. In order to prepare the data for that stage, here we want to bin `SalePrice` based on its median value, *i.e.*, if a property's `SalePrice` is above or equal to the median value of the vector `SalePrice`, the property's `SalePrice` value gets replaced with 1, otherwise 0. <span style=\"color:green\">[2]</span>\n","10. Report the count of ones and zeros in your updated `SalePrice` attribute. Taking it as the target for classification, will that be a balanced or imbalanced classification problem? <span style=\"color:green\">[2]</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUiWJhLubLjq"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"mkDvY2OQbLjq"},"source":["### Q1.2 - <span style=\"color:red\">[8]</span> - Data Splitting\n","In the previous question, you converted `SalePrice` to a discrete variable. Separate it from the rest of the attributes to use it as the target variable for your machine learning model. Split, in a stratified and shuffled fashion, your preprocessed dataset by setting aside 30 percent of the data for testing, and the rest for training. Make sure to use the provided random seed for this purpose. Then, print out class distribution for both ytrain and ytest."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_7Xe9nvbLjq"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"gw60NtuibLjq"},"source":["### Q1.3 - <span style=\"color:red\">[14]</span> - Classifier Model Training and Selection\n","\n","Using `sklearn.linear_model.LogisticRegression` do the following steps:\n","1. Initiate two different Logistic Regression models, namely, \"model1\" and \"model2\". Both use a `max_iter` of $20000$, and `liblinear` for solver. As for the `penalty` argument, \"model1\" and \"model2\" use `l1` and `l2`, respectively.\n","2. With the area under the Receiver Operating Characteristic curve as your scorer, perform 5-fold stratified and shuffled cross-validation to report the CV score of both models. Choose the best model among the two and train it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpaPQBs_bLjq"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"tTt7E5pLbLjq"},"source":["### Q1.4 - <span style=\"color:red\">[6]</span> - Evaluate Winner Model on Test Set\n","Generally, Receiver Operating Characteristic (ROC) curves should be used when there are roughly equal numbers of observations for each class. Precision-Recall (PR) curves should be used when there is a moderate to large class imbalance. Given this information, choose the right type of curve for your winner model and plot it for both training and test sets, also, report the AUC for both sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie67fLY1bLjr"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"3sAkVs2EbLjr"},"source":["### Q1.5 - <span style=\"color:red\">[8]</span> - Fine-Tuning\n","The default threshold value in Sklearn Logistic Regression is 0.5. You are told by the stakeholders that the maximum false positive rate (FPR) which this project can tolerate is 0.2. Based on this information, choose the threshold value which leads to the highest Recall given $FPR \\leq 0.2$. Use the training set to find this threshold value. What would be your new threshold?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ro54HZDabLjr"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"w6hWWIlWbLjr"},"source":["### Q1.6 - <span style=\"color:red\">[6]</span> - Evaluation of Fine-Tuned Model: Accuracy Score\n","Report accuracy scores of the model based on the new threshold (*i.e.*, found in the previous question) for both the training and test sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"asJ92X8PbLjr"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"88Gd24m7bLjr"},"source":["### Q1.7 - <span style=\"color:red\">[8]</span> - Evaluation of Fine-Tuned Model: Confusion Matrix\n","Report the confusion matrix over the test set for both the default and new thresholds. Going from the default to new threshold, by what percentage the sum of false negatives and false positives changed? Did this sum decreased or increased?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6kIyUP2bLjr"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"Nds9OBsWbLjs"},"source":["---\n","## Question 2 - <span style=\"color:red\">[30]</span> - Uncertainty Quantification\n","We have an apparatus which detects and records the amplitude of certain input signals. We have done repeated experiments with this device and have recorded the measured amplitudes of each input signal in \"Data_Q2.csv\", which has the following attributes:\n","\n","|Column Index | Attribute | Description |\n","| --- | --- | --- |\n","| 0|Signal|Input physical signal|\n","| 1|Amplitude|Measured amplitude of input signal|"]},{"cell_type":"markdown","metadata":{"id":"odG6243abLjs"},"source":["### Q2.1 - <span style=\"color:red\">[20]</span> - Bootstrap\n","Using a confidence level of $97\\%$, and a resampling number of $5000$, compute and report the **bootstrap** confidence interval (CI) of the **median** amplitude for each input signal.\n","\n","Feel free to use `scipy.stats.bootstrap` to compute the bootstrap confidence intervals."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uyJpWx6zbLjs"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"eJRrrYnxbLjs"},"source":["### Q2.2 - <span style=\"color:red\">[10]</span> - CI Plot\n","Plot the median of amplitudes for each signal (*i.e.*, x-axis for signal and y-axis for the median of signal amplitude). Your plot must also show the bootstrap CIs' upper and lower bounds. Based on your calculated CIs, for which signal the apparatus is least certain?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuW2lECObLjs"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"rx8bHWkNbLjs"},"source":["---\n","$$ The\\;End $$"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"my_py_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}