{"cells":[{"cell_type":"markdown","metadata":{"id":"izqne0Z6IH__"},"source":["# Assignment 6: Feature selection and regularization\n","\n","# Total: /100\n","\n","## Instructions\n","\n","* Complete the assignment\n","\n","* Once the notebook is complete, **restart** your kernel and **rerun** your cells\n","\n","* Submit this notebook to owl by the deadline\n","\n","* You may use any python library functions you wish to complete the assignment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GTwVRZnbIGrl"},"outputs":[],"source":["# You may need these\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import sklearn as sk\n","import sklearn.linear_model as skl\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.preprocessing import StandardScaler \n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.feature_selection import SequentialFeatureSelector\n","from sklearn.linear_model import LassoCV\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","\n","seed = 2023\n","np.random.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"G4EmPdu-tV-2"},"source":["## Question 1: /20 pts\n","\n","\n","Customer Lifetime Value (CLV) is the total income a business can expect from a customer over the entire period of their relationship. Itâ€™s an important metric as it costs less to keep existing customers than it does to acquire new ones, so increasing the value of your existing customers is a great way to drive growth. We want to predict CLV for an auto insurance company.\n","\n","1. Read in the `Vehicle_Insurance.csv` dataset and display the last 5 rows.\n","2. Conduct the required data preparation."]},{"cell_type":"markdown","metadata":{"id":"8K4pylNyuK5z"},"source":["### 1.1 Read the dataset and display the last 5 rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hW5aHQQoKHtu"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"T48PV8tIvQEF"},"source":["### 1.2 Remove the rows with \"clv\" $> 16000$ as well as those with \"clv\" $< 2200$ from the dataset. What's the shape of the dataframe now?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uT1uSpcHvgC6"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"t6h1-f7sxKJa"},"source":["### 1.3 Using `preprocessing.OneHotEncoder()`, convert all categorical features. Make sure not to add collinear features during the encoding process. Then, display the first 3 rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"roWX2SCqxCDW"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"noBsqu-y1lQU"},"source":["### 1.4 Use `pandas.DataFrame.apply` to apply square root transformation to \"Total.Claim.Amount\" and log to the target variable. And then, create your `X` and `y`. (No training/test splitting yet) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ny_rSAQg4int"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"azwMuwal3eL_"},"source":["### 1.5 Build a new design matrix by applying polynomial expansion on the `X` from Question 1.4.\n","\n","Hint: Specify degree=2 and do NOT include the column with power 0 (i.e., the column with all elements being 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSoq2jdp3dI-"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"qIOYW9ue7nab"},"source":["### 1.6 Standardize your design matrix (from Question 1.5) with `StandardScaler()`, and store the result into a Pandas dataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qfJ-MfR9pLe"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"R0Llj1HB4I_f"},"source":["### 1.7 What is the shape of the resultant DataFrame obtained from question 1.6?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIZcJbe-4inw"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"WT-POfziGnpm"},"source":["## Question 2: /7 pts\n","\n","Split the data into training and test sets. Hold out 30% of observations as the test set.  Pass `random_state=seed` to `train_test_split` to ensure you get the same sets per run. The design matrix to pass in to the splitter function is the dataframe whcih you got in Question 1.6. As for the target, you have created it in Question 1.4."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nA70uSCJMiO"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"2LN9bLXV5H3Q"},"source":["How many observations in your traning data set? What is the average value of the target variable in the traning data set (keep 2 decimal place)?"]},{"cell_type":"markdown","metadata":{"id":"hhxxdCrA59Ur"},"source":["**YOUR ANSWER HERE:** [2pts]\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"JSROy1U56I8Y"},"source":["## Question 3: /23 pts"]},{"cell_type":"markdown","metadata":{"id":"HnTESpfO8g2_"},"source":["### 3.1 Create a SciKit Learn `Ridge` regression object. Using this object, run a ridge regression analysis of the target variable against all the transformed predictor variables using your training data. Include the arguement `alpha=4.0`. In addition, the ridge regression should be fitted with the intercept."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNbYd9YM5QO3"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"TiPa777vIESf"},"source":["### 3.2 Vary the ridge coeficient `alpha` according to the hint. Use `cross_val_score()` to select the best `alpha` based on 'mean_squared_error'. Include the argument `cv=5`. Report the `alpha` that yields the smallest mean_squared_error.   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqbRiqdBICnW"},"outputs":[],"source":["# hint: lam = np.exp(np.linspace(-4,1,10))"]},{"cell_type":"markdown","metadata":{"id":"6sDLY0ZoD2gl"},"source":["### 3.3 Re-fit the ridge regression with `alpha` being the value obtained in the previous question. `Print` the first 3 parameters of your model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdW6-rRKDs0H"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"0Tkm7rYwZhav"},"source":["### 3.4 Fit the linear regression without any penalty, and the regression should be fitted with the intercept. `Print` the first 3 parameters of your model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqo8keT9Z-oz"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"sm7Gr6eXaqzP"},"source":["Comparing the parameters that you obtain in questions 3.3 and 3.4, what do you find?"]},{"cell_type":"markdown","metadata":{"id":"3dWojdSQbD1n"},"source":["**YOUR ANSWER HERE:** [2pts]\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"tWgD5DCS4abp"},"source":["### 3.5 Use your trained model from Question 3.4 to predict over the test set and `print` the first 5 prediction values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZ2kmfb74usy"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"rbzjtW76e1pD"},"source":["## Question 4: /25 pts"]},{"cell_type":"markdown","metadata":{"id":"fVzCvbKUgQUr"},"source":["### 4.1 Consider to fit a Lasso regression to the train dataset. Use `lasso_path()` to show the full path of the first 20 coefficients of the Lasso regression. Include the arguement `eps=8e-3` and `n_alphas=50`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yYkOTzFe1DT"},"outputs":[],"source":["# Draw a plot to show the path. Legend is not required in the plot."]},{"cell_type":"markdown","metadata":{"id":"CS-5Wbsfh7UL"},"source":["Describe the trend that shows in your figure."]},{"cell_type":"markdown","metadata":{"id":"aOig7gYBiFJ0"},"source":["**YOUR ANSWER HERE:** [3pts] \n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"8VqmO6vyjGtm"},"source":["### 4.2 Use the Scikit Learn's cross-validated LASSO to automatically search for the best tuning parameter of the LASSO regression on the training set with intercept. Include arguments `eps=8e-3`, `n_alphas=30`, `tol=0.001`, `cv=5`, and `random_state=seed`. Report the best tuning parameter and the number of the non-zero coefficients in the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcgZDP9kjNHP"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"Czdd73jll-QW"},"source":["### 4.3 Use the Scikit Learn's cross-validated ElasticNet to automatically search for the best tuning parameters of the Elasticnet regression with intercept on the training data set. Include the same argument as question 4.2 as well as `l1_ratio=[.7, .9, .95, .99,1]`. Report the best tuning parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPJuGnkjmcE6"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"yQLwlTQznvfs"},"source":["From the obtained tuning parameters, is the Elasticnet regression model equivalent to the Lasso regression? Briefly describe the reason. "]},{"cell_type":"markdown","metadata":{"id":"imEmw4pdozsc"},"source":["**YOUR ANSWER HERE:** [3pts]\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"mA8w-HPJ93h6"},"source":["## Question 5: /16 pts"]},{"cell_type":"markdown","metadata":{"id":"xGaiH_Y49_Nl"},"source":["### 5.1 Start from the regression model in question 3.4, use `SequentialFeatureSelector()` to conduct the forward selection for the features of the regression model. Include the argument `n_features_to_select=20`. Report the indices of the selected features. \n","\n","FYI: Running this using 8 physical cores took about 1 minute for me."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxGV90gx6nDm"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"QNFD6RQJ_8m3"},"source":["What do you need to change about the argument in your model if you want to conduct a backward selection?"]},{"cell_type":"markdown","metadata":{"id":"8pawMkg5-3j9"},"source":["**YOUR ANSWER HERE:** [2pts] \n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"CBLcnkP71SbP"},"source":["### 5.2 Re-fit the regular linear regression based on the traning set by using the selected features from the question 5.1. Report the first 3 parameters of your model as indicated with the print function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8gVaU4mA6Zw"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"ETqQ_ZMy2oyB"},"source":["## Question 6: /9 pts"]},{"cell_type":"markdown","metadata":{"id":"3V9n4qj68cQn"},"source":["### 6.1 Make predictions on the test set using your models in questions 3.3, 4.2, 4.3, and 5.2, respectively. Together with the predicted values obtained in question 3.5, report the first 5 rows of predicted values obtained from different models in a single DataFrame."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcjWPGH82stF"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"jyZgAOlNAKxs"},"source":["### 6.2 Use `mean_squared_error()` to assess the performance of different models based on all the predicted values mentioned in Question 6.1.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnDTK5XG6k08"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"C29Tjgo6A-eH"},"source":["Which model yields the smallest mean squared error on the test dataset?"]},{"cell_type":"markdown","metadata":{"id":"rOXIpNBmBcay"},"source":["**YOUR ANSWER HERE:** [2pts]\n","\n","..."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"my_py_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"33450fd3005a3f920860570602bb6b9ad3febc9347ad497c595fea1c977e6b53"}}},"nbformat":4,"nbformat_minor":0}