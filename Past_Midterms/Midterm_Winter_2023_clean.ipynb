{"cells":[{"cell_type":"markdown","metadata":{"id":"uv6HvUq1TH2z"},"source":["---\n","# <span style=\"color:pink\">DS3000B - DS9000B Midterm Exam</span>\n","\n","## <span style=\"color:pink\">Student ID #: _________</span>\n","\n","## <span style=\"color:pink\">Grade: __ / 100</span>\n","\n","## <span style=\"color:pink\">General Comments</span>\n","\n","- This exam integrates knowledge and skills acquired in the first half of the term. \n","\n","- Use of chatbots, *e.g.* ChatGPT, is prohibited.\n","\n","- You are allowed to use any document and source on your computer and the internet, but you are **not** allowed to share documents, post questions to online forums (this includes use of homework helpers such as Chegg), or communicate in any way with people inside or outside the venue. \n","\n","- Having any communication tools (e.g. Discord, Teams, Outlook etc.) either web-based or app-based open on your computer (or having them running in the background) is considered an act of cheating and you will receive 0 mark for the exam.\n","\n","- To finish the midterm in the alloted time, you will have to work efficiently. Read the entirety of each question carefully.\n","\n","- You must have your work submitted by 7:00PM to the \"Test and Quizzes\" section of the course's site on OWL, *i.e.* the same place where you originally downloaded the notebook. Late submission will be scored with 0 mark. Therefore, to avoid technical difficulties, start your submission, at the latest, five to ten minutes before the deadline.  \n","\n","- Some questions demand a **written answer** - answer these in a full English sentence in markdown cells. \n","\n","- For your figures, ensure that all axes are labeled in an informative way. To facilitate interpretation, there could be a situation where you should limit the x-axis and/or y-axis to zoom-in.\n","\n","- At the end, before submitting to OWL, restart the kernel and rerun all cells to make sure that your notebook runs error free and as expected. \n","\n","## <span style=\"color:pink\">Additional Guidance</span>\n","\n","- The \"Toolbox\" cells offer almost every tool that you need to answer the questions, however, depending on your answers, there could be a couple of instances where you'd need to bring in more tools - unless a question imposes some restrictions.\n","- If at any point you are asking yourself \"are we supposed to...\", write your assumptions clearly and proceed according to them.\n","- If you have no clue how to approach a question, skip it, and move on. Revisit the skipped one(s) after you are done with the other questions.\n","- Where applicable, take advantage of the argument `n_jobs=-1` to speed up processes with parallel computing.\n","- To navigate within the notebook, better to take advantage of the notebook's table of contents (normally on the left side of the screen). It saves you time compared to pure mouse scrolling. In VScode, it is nested under the \"OUTLINE\" tab which is by default minimized unless you click it to maximize.\n"]},{"cell_type":"markdown","metadata":{"id":"krmFdaJFTH25"},"source":["---\n","## <span style=\"color:orange\">Global Toolbox</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGrzz7JeTH3B"},"outputs":[],"source":["import warnings; warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np; seed = 2023; np.random.seed(seed)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"3_mDwk7vTH3D"},"source":["---\n","## Question 1 - <span style=\"color:green\">[60]</span> - Regression\n","Connor Andrew McDavid is a Canadian professional ice hockey player and captain of the Edmonton Oilers of the National Hockey League (NHL). The data file `hockey.csv` provides a reduced version of Connor's game by game career data available on this [website](https://moneypuck.com/data.htm). Each row represents the stats of one game and we want to build a regression model to predict how much time does Connor play each game.\n","\n","The dataset has the following attributes:\n","\n","|#| Attribute | Description |\n","| --- | --- | --- |\n","|0|`opposingTeam`|The team the player played against.|\n","|1|`home_or_away`|Whether a game was played home or away.|\n","|2|`icetime`|Total time the player played in seconds.|\n","|3|`gameScore`|Game score rating.|\n","|4|`I_F_primaryAssists`|Primary Assists the player has received on teammates' goals.|\n","|5|`I_F_secondaryAssists`|Secondary Assists the player has received on teammates' goals.|\n","|6|`I_F_shotAttempts`|Shot attempts. Includes player's shots on goal, missed shots, and blocked shot attempts.|\n","|7|`I_F_goals`|Number of goals the player scored.|\n","|8|`I_F_rebounds`|Rebound shot attempts. These must occur within 3 seconds of a previous shot.|\n","|9|`I_F_reboundGoals`|Goals from rebound shot attempts.|\n","|10|`I_F_freeze`|Puck freezes after a player's shot. The  number of puck freezes by goalies after the player's unblocked shot attempts.|\n","|11|`I_F_playContinuedInZone`|Number of times the play continues in the offensive zone after the player's shot besides an immediate rebound shot.|\n","|12|`I_F_playContinuedOutsideZone`|Number of times the play goes outside the offensive zone after the player's shot.|\n","|13|`I_F_savedShotsOnGoal`|Number of the player's unblocked shots that were saved by the goalie.|\n","|14|`I_F_savedUnblockedShotAttempts`|Number of the player's unblocked shots that were saved by the goalie or missed the net.|\n","|15|`I_F_penalityMinutes`|Number of penalty minutes the player has received.|\n","|16|`I_F_faceOffsWon`|Number of faceoffs the player has won.|\n","|17|`I_F_hits`|Number of hits the player has given.|\n","|18|`I_F_takeaways`|Number of takeaways the player has taken from opponents.|\n","|19|`I_F_giveaways`|Number of giveaways the player has given to other team.|\n","|20|`I_F_lowDangerGoals`|Goals from low danger shots.|\n","|21|`I_F_mediumDangerGoals`|Goals from medium danger shots.|\n","|22|`I_F_highDangerGoals`|Goals from high danger shots.|\n","|23|`I_F_unblockedShotAttempts`|All shot attempts that weren't blocked.|\n","|24|`I_F_dZoneGiveaways`|Giveaways in the team's defensive zone.|\n","|25|`penalityMinutesDrawn`|Number of penalty minutes the player has drawn.|\n","|26|`penaltiesDrawn`|Number of penalties the player has drawn.|"]},{"cell_type":"markdown","metadata":{"id":"qqmCBd_RTH3G"},"source":["### <span style=\"color:orange\">Q1 Toolbox</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mH6OML9CTH3G"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression, LassoCV\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"markdown","metadata":{"id":"P_z2BJXGTH3H"},"source":["### Q1.1 - <span style=\"color:red\">[6]</span> - Load the dataset and answer the following questions according to the data:\n","\n","1. How many games in total has Connor played? How many of them were \"HOME\" and how many of them were \"AWAY\" matches?\n","2. On average, how many minutes per game Connor's been on ice?\n","4. How many unique teams has Connor played against?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7UhtXRnTH3J"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"RYS5rl31TH3K"},"source":["### Q1.2 - <span style=\"color:red\">[14]</span> - We want to retain the categorical attributes in the matrix of features, hence apply a proper encoding to take care of them. Then, split the data into training and test sets with `test_size=0.3` and `random_state=seed`. Instantiate an object from the `sklearn.linear_model.LinearRegression` class with default arguments, train, and report its training RMSE, test RMSE, as well as the mean and standard deviation of its shuffled cross-validated RMSE over 5 folds. Comment on the performance of this model in the context of overfitting/underfitting.\n","\n","For shuffling, use the notebook random seed (defined in \"Global Toolbox\" as `seed`). "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ul8iaFcTH3Q"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"U1blqycmTH3R"},"source":["### Q1.3 - <span style=\"color:red\">[7]</span> - Report the top 2 positively correlated features as well as the top negatively correlated feature with respect to the target variable. In writing, interpret the relationships of both groups with respect to the target variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKHanILvTH3S"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"DCGniIfATH3T"},"source":["### Q1.4 - <span style=\"color:red\">[8]</span> - Use Seaborn's `pairplot()` to investigate the pair-wise joint density (bivariate density contour curves) of the top 2 positively correlated attributes and target. The diagonal tiles of the output picture must be the univariate density curve of the attributes. Level both groups of tiles, non-diagonal and diagonal, on the \"home_or_away\" attribute (for this can simply set `hue=\"home_or_away\"`). If you are asked to **qualitatively** judge (**solely based on what you've plotted here**) whether the feature \"home_or_away\" is an important predictor, what would you answer?\n","\n","To facilitate interpretation, you can also set argument `corner=True` to output only the diagonal tiles and the tiles below the diagonal."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4Q9xh8aTH3U"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"t66BeYw2TH3V"},"source":["### Q1.5 - <span style=\"color:red\">[9]</span> - You just saw in the diagonal tiles of the figure produced in the previous question (*i.e.*, Q1.4) that the univariate distributions of attributes \"icetime\", \"I_F_shotAttempts\" and \"I_F_faceOffsWon\" are skewed to the left; let's transform them using `np.log10`. Then, instantiate an object from the `sklearn.linear_model.LinearRegression` class with default arguments and train it. For this new model, report the same metrics as you did in Q1.2, *i.e.*, training RMSE, test RMSE, as well as the mean and standard deviation of shuffled cross-validated RMSE over 5 folds. Compare the scores against that of trained in Question 1.2. Which model would you choose?\n","\n","Caveat: When doing the $log10$ transformation, watch out for values for which the function is undefined. You need to take care of them without introducing new bias to the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zGadkGSTH3W"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"yuwy9OZ2TH3W"},"source":["### Q1.6 - <span style=\"color:red\">[16]</span> - Instantiate and train a cross-validated LASSO object with 5 folds and `random_state=seed`. For the constant that multiplies the penalty term, use a range of numbers from $1e-3$ to $2e-3$ inclusive with a step size of $1e-4$. In other words, $11$ equally spaced values from $1e-3$ to $2e-3$ inclusive. Answer the following questions:\n","1. What is the model's training RMSE, test RMSE, as well as the mean and standard deviation of shuffled cross-validated RMSE over 5 folds?\n","2. How does this model perform compared with the previous model, *i.e.*, the one trained in Q1.5?\n","3. What is the best regularization strength value that the model finds?\n","4. Compare the average of the absolute values of the fitted parameters of this model against that of the previous model (Q1.5). What do you observe? \n","5. Pay closer attention to the fitted parameters of this model. Do you see any zero values? What does it mean and report their corresponding feature names.\n","6. Which predictor does this model rate as the most important one?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1y8UtBcTH3Z"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"TAqyPWAHTH3Z"},"source":["---\n","## Question 2 - <span style=\"color:green\">[40]</span> - Classification\n","In this question, we want to train a classifier using the same dataset but with the \"home_or_away\" attribute as target. Start with loading the tools and dataset by executing the toolbox cell below."]},{"cell_type":"markdown","metadata":{"id":"Z-0njNdVTH3d"},"source":["### <span style=\"color:orange\">Q2 Toolbox</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bz_ypqrKTH3e"},"outputs":[],"source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import make_scorer, RocCurveDisplay, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve\n","from sklearn.pipeline import Pipeline\n","\n","df2 = pd.read_csv('hockey.csv').drop('opposingTeam', axis=1)\n","df2.head()"]},{"cell_type":"markdown","metadata":{"id":"Bqso8n75TH3f"},"source":["### Q2.1 - <span style=\"color:red\">[5]</span> - Answer the following questions:\n","1. Is this a binary or multiclass classification problem? Name the labels.\n","2. Can we say, qualitatively, that this is a balanced classification problem?\n","3. What label is the majority class?\n","4. What is the baseline accuracy for this dataset? What does it mean?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zx9fbuCmTH3f"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"1dm_xCwATH3g"},"source":["### Q2.2 - <span style=\"color:red\">[3]</span> - Do stratified training/test split on `df2` with `test_size=0.3`, `random_state=seed`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cQcGk4vTH3h"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"RbhRVL4zTH3h"},"source":["### Q2.3 - <span style=\"color:red\">[7]</span> - Do/answer the following steps/questions:\n","\n","1. Instantiate a **logistic regression** model with **Ridge regularization** from the `sklearn.linear_model.SGDClassifier` class.\n","2. In terms of their approaches to find the best parameters, how the model created in step #1 would be different from a model instantiated from the `sklearn.linear_model.LogisticRegression` class?\n","3. Should you apply any type of scaling to the data before training the model created in step #1? Why?\n","4. If you need a scaler, put it together with your model into a pipeline. If you do not need a scaler, still create a pipeline using the model only."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUpDYll2TH3i"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"PR6TMh5CTH3i"},"source":["### Q2.4 - <span style=\"color:red\">[5]</span> - We want to cross-validate the pipeline created in Q2.3 using 5 stratified validation sets. But for the scoring part of the cross-validation, we want to use **error rate** which is defined as $(1-Accuracy)$. First, define a function that takes as input arguments y_true and y_pred, and returns $(1-Accuracy)$. Then, run cross-validation with your custom function as its scorer. Report the mean and standard deviation of the cross-validated **error rate** of your pipeline.\n","\n","Hint: You may use `make_scorer()` to create a scorer out of your custom function. For example:\n","```\n","cross_validate( model, Xtrain, ytrain, cv='YourChosenStrategy', scoring=make_scorer(NameOfYourCustomFunction), n_jobs=-1 )\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1E8hA5FPTH3i"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"-gMXWKM-TH3j"},"source":["### Q2.5 - <span style=\"color:red\">[3]</span> - Create another pipeline similar to the previous one (in Q2.3) with the only difference being the regularization part. Because, this time you want to use LASSO regularization. Cross-validate it in the same way as you did with the previous pipeline (*i.e.*, in Q 2.4). Report the mean and standard deviation of cross-validated **error rate** for this new pipeline over 5 stratified validation sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULqUf0IhTH3j"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"x-eM3ECrTH3k"},"source":["### Q2.6 - <span style=\"color:red\">[2]</span> - Answer these:\n","1. Among the models cross-validated in Q 2.4 and Q 2.5, which one would you pick, why?\n","2. What is the accuracy of your chosen model? Is it worth further investigating the model?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOiU2iR6TH3l"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"Kq9-veg4TH3m"},"source":["### Q2.7 - <span style=\"color:red\">[3]</span> - Report the Confusion Matrix for the best model. Identify and explain the entries (of the matrix) where your model is doing good and report their values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bzk0oe9gTH3n"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"BgYyb_FBTH3o"},"source":["### Q2.8 - <span style=\"color:red\">[2]</span> - To your model, what label is the negative class and what label is the positive class?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtvZ_HVoTH3o"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"0a_fafs5TH3o"},"source":["### Q2.9 - <span style=\"color:red\">[6]</span> - Plot Recall vs Precision for your model over the test set. The stakeholder of the project tells you that they require a minimum recall of 0.1. Answer the following questions:\n","1. Roughly, what would be the precision of the best model that you can hand over to them?\n","2. What value should you set for the threshold of the sigmoid function to have your model tuned according to the requirement of the stakeholder?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"seq6lfYyTH3p"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"kYimsDqSTH3t"},"source":["### Q2.10 - <span style=\"color:red\">[4]</span> - Use `classification_report()` to report the classification metrics of your model over the test set. Answer the following questions based on the output:\n","1. Out of all the games that the model predicted as \"away\", what percent were actually \"away\"?\n","2. What percentage of the negative class in the sample does the model correctly identify?\n","\n","Caveat: In your writing, you must make reference to the metric which you are using from the output to support your answer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDIPU_lhTH3u"},"outputs":[],"source":["#"]},{"cell_type":"markdown","metadata":{"id":"p98VV_WwTH3v"},"source":["---\n","# Warning!\n","\n","After uploading your completed notebook to OWL, make sure to click the \"Submit for Grading\" button and confirm your submission. If your submission is successful, you should receive a confirmation email in your UWO inbox.\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"my_py_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"33450fd3005a3f920860570602bb6b9ad3febc9347ad497c595fea1c977e6b53"}}},"nbformat":4,"nbformat_minor":0}
